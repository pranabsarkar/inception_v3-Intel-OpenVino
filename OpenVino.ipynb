{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenVino.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnLToafbUQax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# C:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\inference_engine\\samples\\python_samples\\classification_sample\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3 as Net\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "img_height = 224\n",
        "\n",
        "model = Net(weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erN3d5DjUTiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optional image to test model prediction.\n",
        "img_path = 'data/elephant.jpg'\n",
        "\n",
        "# Path to save the model h5 file.\n",
        "model_fname = 'model/model.h5'\n",
        "\n",
        "# Load the image for prediction.\n",
        "img = image.load_img(img_path, target_size=(img_height, img_height))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "# decode the results into a list of tuples (class, description, probability)\n",
        "# (one such list for each sample in the batch)\n",
        "print('Predicted:', decode_predictions(preds, top=3)[0])\n",
        "# Predicted: [(u'n02504013', u'Indian_elephant', 0.82658225), (u'n01871265', u'tusker', 0.1122357), (u'n02504458', u'African_elephant', 0.061040461)]\n",
        "\n",
        "# Save the h5 file to path specified.\n",
        "model.save(model_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJF_-lyWUZ3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import graph_io\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "# Clear any previous session.\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "save_pb_dir = 'model/'\n",
        "model_fname = 'model/model.h5'\n",
        "def freeze_graph(graph, session, output, save_pb_dir='.', save_pb_name='frozen_model.pb', save_pb_as_text=False):\n",
        "    with graph.as_default():\n",
        "        graphdef_inf = tf.graph_util.remove_training_nodes(graph.as_graph_def())\n",
        "        graphdef_frozen = tf.graph_util.convert_variables_to_constants(session, graphdef_inf, output)\n",
        "        graph_io.write_graph(graphdef_frozen, save_pb_dir, save_pb_name, as_text=save_pb_as_text)\n",
        "        return graphdef_frozen\n",
        "\n",
        "# This line must be executed before loading Keras model.\n",
        "tf.keras.backend.set_learning_phase(0) \n",
        "\n",
        "model = load_model(model_fname)\n",
        "\n",
        "session = tf.keras.backend.get_session()\n",
        "\n",
        "INPUT_NODE = [t.op.name for t in model.inputs]\n",
        "OUTPUT_NODE = [t.op.name for t in model.outputs]\n",
        "print(INPUT_NODE, OUTPUT_NODE)\n",
        "frozen_graph = freeze_graph(session.graph, session, [out.op.name for out in model.outputs], save_pb_dir=save_pb_dir)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h0BxN2PUc1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# force reset ipython namespaces\n",
        "%reset -f\n",
        "\n",
        "import platform\n",
        "is_win = 'windows' in platform.platform().lower()\n",
        "\n",
        "# OpenVINO 2019\n",
        "if is_win:\n",
        "    mo_tf_path = '\"C:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\model_optimizer\\mo_tf.py\"'\n",
        "else:\n",
        "    # mo_tf.py path in Linux\n",
        "    mo_tf_path = '/opt/intel/openvino/deployment_tools/model_optimizer/mo_tf.py'\n",
        "\n",
        "pb_file = 'model/frozen_model.pb'\n",
        "output_dir = 'model/'\n",
        "img_height = 224\n",
        "input_shape = [1, img_height, img_height, 3]\n",
        "input_shape_str = str(input_shape).replace(' ', '')\n",
        "input_shape_str"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm4zzlH6UfTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python {mo_tf_path} --input_model {pb_file} --output_dir {output_dir} --input_shape {input_shape_str} --data_type FP16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZqBEs5UUhg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import platform\n",
        "import os\n",
        "\n",
        "\n",
        "# Check path  exists in `PYTHONPATH`.\n",
        "is_win = 'windows' in platform.platform().lower()\n",
        "\n",
        "\"\"\" \n",
        "# OpenVINO 2018.\n",
        "if is_win:\n",
        "    message = \"Please run `C:\\\\Intel\\\\computer_vision_sdk\\\\bin\\\\setupvars.bat` before running this.\"\n",
        "else:\n",
        "    message = \"Add the following line to ~/.bashrc and re-run.\\nsource ~/intel/computer_vision_sdk/bin/setupvars.sh\"\n",
        "\"\"\"\n",
        "\n",
        "# OpenVINO 2019.\n",
        "if is_win:\n",
        "    message = 'Please run \"C:\\Program Files (x86)\\IntelSWTools\\openvino\\bin\\setupvars.bat\" before running this.'\n",
        "else:\n",
        "    message = \"Add the following line to ~/.bashrc and re-run.\\nsource /opt/intel/openvino/bin/setupvars.sh\"\n",
        "\n",
        "assert 'computer_vision_sdk' in os.environ['PYTHONPATH'] or 'openvino' in os.environ['PYTHONPATH'], message\n",
        "\n",
        "try:\n",
        "    from openvino import inference_engine as ie\n",
        "    from openvino.inference_engine import IENetwork, IEPlugin\n",
        "except Exception as e:\n",
        "    exception_type = type(e).__name__\n",
        "    print(\"The following error happened while importing Python API module:\\n[ {} ] {}\".format(exception_type, e))\n",
        "    sys.exit(1)\n",
        "\n",
        "def pre_process_image(imagePath, img_height=224):\n",
        "    # Model input format\n",
        "    n, c, h, w = [1, 3, img_height, img_height]\n",
        "    image = Image.open(imagePath)\n",
        "    processedImg = image.resize((h, w), resample=Image.BILINEAR)\n",
        "\n",
        "    # Normalize to keep data between 0 - 1\n",
        "    processedImg = (np.array(processedImg) - 0) / 255.0\n",
        "\n",
        "    # Change data layout from HWC to CHW\n",
        "    processedImg = processedImg.transpose((2, 0, 1))\n",
        "    processedImg = processedImg.reshape((n, c, h, w))\n",
        "\n",
        "    return image, processedImg, imagePath\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-BfXauvUkbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plugin initialization for specified device and load extensions library if specified.\n",
        "plugin_dir = None\n",
        "model_xml = 'model/frozen_model.xml'\n",
        "model_bin = 'model/frozen_model.bin'\n",
        "# Devices: GPU (intel), CPU, MYRIAD\n",
        "plugin = IEPlugin(\"MYRIAD\", plugin_dirs=plugin_dir)\n",
        "# Read IR\n",
        "net = IENetwork(model=model_xml, weights=model_bin)\n",
        "assert len(net.inputs.keys()) == 1\n",
        "assert len(net.outputs) == 1\n",
        "input_blob = next(iter(net.inputs))\n",
        "out_blob = next(iter(net.outputs))\n",
        "# Load network to the plugin\n",
        "exec_net = plugin.load(network=net)\n",
        "del net\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfWWnLMuUnLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "def img_view(file_name):\n",
        "    im = cv2.imread(file_name)\n",
        "    plt.imshow(im)\n",
        "    plt.title('Selected picture')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maaXVLlIUsD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vPDZQA9Uuss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run inference\n",
        "\n",
        "for i in range(1,6):\n",
        "    fileName = 'Data/'+str(i)+'.jpg'\n",
        "    image, processedImg, imagePath = pre_process_image(fileName)\n",
        "    res = exec_net.infer(inputs={input_blob: processedImg})\n",
        "    # Access the results and get the index of the highest confidence score\n",
        "    output_node_name = list(res.keys())[0]\n",
        "    res = res[output_node_name]\n",
        "    idx = np.argsort(res[0])[-1]\n",
        "    idx\n",
        "\n",
        "    from tensorflow.keras.applications.inception_v3 import decode_predictions\n",
        "    print(\"Image:\",i)\n",
        "    img_view(fileName)\n",
        "    print('Predicted:', decode_predictions(res, top=3)[0])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}